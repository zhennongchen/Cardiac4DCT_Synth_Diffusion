{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVF synthesis using trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import torch\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "from ema_pytorch import EMA\n",
    "from scipy.ndimage import zoom\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_diffusion_3D as ddpm_3D\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_EDM as edm\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_EDM_warp as edm_warp\n",
    "import Cardiac4DCT_Synth_Diffusion.Build_lists.Build_list as Build_list\n",
    "import Cardiac4DCT_Synth_Diffusion.Generator as Generator\n",
    "import Cardiac4DCT_Synth_Diffusion.functions_collection as ff\n",
    "main_path = '/mnt/camca_NAS/4DCT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: set default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'MVF_EDM'\n",
    "\n",
    "how_many_timeframes_together = 10\n",
    "picked_tf = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "mvf_size_3D = [40,40,24]\n",
    "mvf_slice_range = [0,96]\n",
    "mvf_folder = os.path.join(main_path,'example_data/mvf_warp0_onecase')\n",
    "\n",
    "downsample_list =  (True, True, False, False) \n",
    "\n",
    "augment_pre_done = True # done in step2 jupyter notebook\n",
    "conditional_diffusion_timeframe = False\n",
    "conditional_diffusion_image = True\n",
    "conditional_diffusion_EF = True \n",
    "conditional_diffusion_seg = False\n",
    "\n",
    "save_folder = os.path.join(main_path, 'example_data/models', trial_name, 'pred_mvf'); os.makedirs(save_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: define pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_filename = os.path.join(main_path, 'example_data/models', trial_name, 'models/model-final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: define patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define training and validation data\n",
    "data_sheet = os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list.xlsx')\n",
    "\n",
    "b = Build_list.Build(data_sheet)\n",
    "patient_class_list, patient_id_list,_ = b.__build__(batch_list = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: define diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define diffusion model\n",
    "model = ddpm_3D.Unet3D_tfcondition(\n",
    "    init_dim = 64,\n",
    "    channels = 3 * how_many_timeframes_together,\n",
    "    out_dim = 3 * how_many_timeframes_together,\n",
    "    # conditional_timeframe_input_dim = None,\n",
    "    # conditional_diffusion_timeframe = conditional_diffusion_timeframe,\n",
    "    conditional_diffusion_image = conditional_diffusion_image,\n",
    "    conditional_diffusion_EF = conditional_diffusion_EF,\n",
    "    conditional_diffusion_seg = conditional_diffusion_seg, # should be False\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    downsample_list = downsample_list,\n",
    "    upsample_list = (downsample_list[2], downsample_list[1], downsample_list[0], False),\n",
    "    flash_attn = False, \n",
    "    full_attn = (None, None, False, False), )\n",
    "\n",
    "diffusion_model = edm.EDM(\n",
    "    model,\n",
    "    image_size = mvf_size_3D,\n",
    "    num_sample_steps = 50,\n",
    "    clip_or_not = True,\n",
    "    clip_range = [-1,1],)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5: generate MVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_class: example_data patient_id: example_1\n",
      "EF: 0.68\n",
      "data_condition_EF:  tensor([[0.6800]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 50/50 [00:01<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EF predicted:  tensor([[0.7035]], device='cuda:0')\n",
      "EF: 0.22\n",
      "data_condition_EF:  tensor([[0.2200]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 50/50 [00:01<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EF predicted:  tensor([[0.1645]], device='cuda:0')\n",
      "patient_class: example_data patient_id: example_2\n",
      "EF: 0.31\n",
      "data_condition_EF:  tensor([[0.3100]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 50/50 [00:01<00:00, 29.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EF predicted:  tensor([[0.2804]], device='cuda:0')\n",
      "EF: 0.13\n",
      "data_condition_EF:  tensor([[0.1300]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling time step: 100%|██████████| 50/50 [00:01<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EF predicted:  tensor([[0.1121]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(0,patient_class_list.shape[0]):\n",
    "    \n",
    "    patient_class = patient_class_list[i]\n",
    "    patient_id = patient_id_list[i]\n",
    "    print('patient_class:', patient_class, 'patient_id:', patient_id)\n",
    "\n",
    "    ff.make_folder([os.path.join(save_folder, patient_class), os.path.join(save_folder, patient_class, patient_id)])\n",
    "\n",
    "    for round_test in range(0,2): # one factual synthesis, one counterfactual synthesis\n",
    "\n",
    "        # get EF\n",
    "        timeframe_info = pd.read_excel(os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list_final_selection_timeframes.xlsx'))\n",
    "        row = timeframe_info[timeframe_info['patient_id'] == patient_id]\n",
    "        preset_EF = round(row['EF_sampled_in_10tf_by_mvf'].iloc[0],2)\n",
    "\n",
    "        sampled_time_frame_list = ast.literal_eval(row['sampled_time_frame_list'].iloc[0])\n",
    "        normalized_time_frame_list = ast.literal_eval(row['normalized_time_frame_list_copy'].iloc[0])\n",
    "\n",
    "        if round_test > 0 and conditional_diffusion_EF:\n",
    "            # randomly get a new EF \n",
    "            preset_EF = round(np.random.uniform(0.10,0.80),2)\n",
    "        print('EF:', preset_EF)\n",
    "\n",
    "        save_folder_case = os.path.join(save_folder,patient_class, patient_id, 'test_'+ str(round_test))\n",
    "        os.makedirs(save_folder_case, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(save_folder_case, 'EF.txt'), 'w') as f:\n",
    "                f.write(str(preset_EF))\n",
    "\n",
    "        generator = Generator.Dataset_dual_3D(\n",
    "\n",
    "            patient_class_list = np.asarray([patient_class]),\n",
    "            patient_id_list = np.asarray([patient_id]),\n",
    "            main_path = main_path,\n",
    "            timeframe_info = timeframe_info,\n",
    "            \n",
    "            how_many_timeframes_together = how_many_timeframes_together,\n",
    "\n",
    "            mvf_size_3D = mvf_size_3D,\n",
    "            slice_range = mvf_slice_range,\n",
    "            \n",
    "            picked_tf = picked_tf,\n",
    "            preset_EF = preset_EF,\n",
    "            condition_on_image = True,\n",
    "            prepare_seg = True,\n",
    "            mvf_cutoff = [-20,20],\n",
    "            augment = False,\n",
    "            augment_pre_done= augment_pre_done,)\n",
    "\n",
    "        sampler = edm.Sampler(diffusion_model,generator,batch_size = 1,image_size =  mvf_size_3D,)\n",
    "\n",
    "        save_file = os.path.join(save_folder_case, 'pred_mvf.nii.gz')\n",
    "        original_image_file = os.path.join(main_path,'example_data/nii-images',patient_class, patient_id, 'img-nii-resampled-1.5mm/0.nii.gz')\n",
    "\n",
    "        pred_mvf_torch, EF_pred, pred_mvf_numpy = sampler.sample_3D_w_trained_model(trained_model_filename=trained_model_filename,cutoff_min = -20, cutoff_max = 20,\n",
    "                    save_file = save_file,  patient_class = patient_class, patient_id = patient_id,image_file = original_image_file,)\n",
    "                \n",
    "        EF_pred = EF_pred.cpu().detach().numpy()[0][0] if isinstance(EF_pred, torch.Tensor) else EF_pred\n",
    "\n",
    "        result.append([patient_class, patient_id, round_test, preset_EF, EF_pred])\n",
    "        df = pd.DataFrame(result, columns=['patient_class', 'patient_id', 'round_test', 'preset_EF', 'pred_EF'])\n",
    "        df.to_excel(os.path.join(os.path.dirname(save_folder), 'EF_results.xlsx'), index=False)\n",
    "\n",
    "        # save in original resolution\n",
    "        if os.path.isfile(os.path.join(save_folder_case, 'pred_tf'+ str(sampled_time_frame_list[-1])+'_x.nii.gz')) == 0:\n",
    "            image_file = os.path.join(main_path,'example_data/nii-images',patient_class, patient_id, 'img-nii-resampled-1.5mm/0.nii.gz')\n",
    "            affine = nb.load(image_file).affine\n",
    "            for ii in range(len(sampled_time_frame_list)):\n",
    "                segment_range = [3*ii, 3*(ii+1)]\n",
    "                mvf1 = pred_mvf_numpy[3*ii:3*(ii+1),...]; mvf1 = np.moveaxis(mvf1, 0, -1)\n",
    "     \n",
    "                mvf1 = zoom(mvf1, (4,4,4,1), order=1) # upsample to original resolution\n",
    "                nb.save(nb.Nifti1Image(mvf1[:,:,:,0], affine), os.path.join(os.path.dirname(save_file), 'pred_tf'+str(sampled_time_frame_list[ii])+'_x.nii.gz'))\n",
    "                nb.save(nb.Nifti1Image(mvf1[:,:,:,1], affine), os.path.join(os.path.dirname(save_file), 'pred_tf'+str(sampled_time_frame_list[ii])+'_y.nii.gz'))\n",
    "                nb.save(nb.Nifti1Image(mvf1[:,:,:,2], affine), os.path.join(os.path.dirname(save_file), 'pred_tf'+str(sampled_time_frame_list[ii])+'_z.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

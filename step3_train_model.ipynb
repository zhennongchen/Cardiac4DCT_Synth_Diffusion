{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "In this script, we perform the model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/Documents/Cardiac4DCT_Synth_Diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch/conditional_diffusion_3D.py:882: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "from ema_pytorch import EMA\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_diffusion_3D as ddpm_3D\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_EDM as edm\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_EDM_warp as edm_warp\n",
    "import Cardiac4DCT_Synth_Diffusion.Build_lists.Build_list as Build_list\n",
    "import Cardiac4DCT_Synth_Diffusion.Generator as Generator\n",
    "main_path = '/mnt/camca_NAS/4DCT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: set some default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'MVF_EDM' \n",
    "EF_loss_weight = 1\n",
    "\n",
    "how_many_timeframes_together = 10\n",
    "picked_tf = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "pre_trained_model = None\n",
    "start_step = 0\n",
    "\n",
    "mvf_size_3D = [40,40,24]\n",
    "mvf_slice_range = [0,96]\n",
    "mvf_folder = os.path.join(main_path,'example_data/mvf_warp0_onecase')\n",
    "\n",
    "downsample_list =  (True, True, False, False) \n",
    "\n",
    "augment_pre_done = True # done in step2 jupyter notebook\n",
    "conditional_diffusion_timeframe = False\n",
    "conditional_diffusion_image = True\n",
    "conditional_diffusion_EF = True \n",
    "conditional_diffusion_seg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: define your own train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_class_train_list: 2  patient_class_val_list: 2\n"
     ]
    }
   ],
   "source": [
    "# # define training and validation data\n",
    "data_sheet = os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list.xlsx')\n",
    "\n",
    "b = Build_list.Build(data_sheet)\n",
    "patient_class_train_list, patient_id_train_list,_ = b.__build__(batch_list = [0])\n",
    "patient_class_val_list = patient_class_train_list\n",
    "patient_id_val_list = patient_id_train_list\n",
    "\n",
    "print('patient_class_train_list:', len(patient_class_train_list), ' patient_class_val_list:', len(patient_class_val_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: define diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define diffusion model\n",
    "model = ddpm_3D.Unet3D_tfcondition(\n",
    "    init_dim = 64,\n",
    "    channels = 3 * how_many_timeframes_together,\n",
    "    out_dim = 3 * how_many_timeframes_together,\n",
    "    # conditional_timeframe_input_dim = None,\n",
    "    # conditional_diffusion_timeframe = conditional_diffusion_timeframe,\n",
    "    conditional_diffusion_image = conditional_diffusion_image,\n",
    "    conditional_diffusion_EF = conditional_diffusion_EF,\n",
    "    conditional_diffusion_seg = conditional_diffusion_seg, # should be False\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    downsample_list = downsample_list,\n",
    "    upsample_list = (downsample_list[2], downsample_list[1], downsample_list[0], False),\n",
    "    flash_attn = False, \n",
    "    full_attn = (None, None, False, False), )\n",
    " \n",
    "diffusion_model = edm.EDM(\n",
    "    model,\n",
    "    image_size = mvf_size_3D,\n",
    "    num_sample_steps = 50,\n",
    "    clip_or_not = False,) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: define generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "timeframe_info = pd.read_excel(os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list_final_selection_timeframes.xlsx'))\n",
    "\n",
    "generator_train = Generator.Dataset_dual_3D(\n",
    "    patient_class_list = patient_class_train_list,\n",
    "    patient_id_list = patient_id_train_list,\n",
    "    main_path = main_path,\n",
    "    timeframe_info = timeframe_info,\n",
    "    \n",
    "    how_many_timeframes_together = how_many_timeframes_together,\n",
    "\n",
    "    mvf_size_3D = mvf_size_3D,\n",
    "    slice_range = mvf_slice_range,\n",
    "    \n",
    "    picked_tf = picked_tf,\n",
    "    condition_on_image = True,\n",
    "    prepare_seg = True,\n",
    "    mvf_cutoff = [-20,20],\n",
    "    shuffle = True,\n",
    "    augment = True,\n",
    "    augment_frequency = 0.8, \n",
    "    augment_pre_done = augment_pre_done,\n",
    "    augment_aug_index = [1,2])\n",
    "\n",
    "generator_val = Generator.Dataset_dual_3D(\n",
    "    patient_class_list = patient_class_train_list,\n",
    "    patient_id_list = patient_id_train_list,\n",
    "    main_path = main_path,\n",
    "    timeframe_info = timeframe_info,\n",
    "    \n",
    "    how_many_timeframes_together = how_many_timeframes_together,\n",
    "\n",
    "    mvf_size_3D = mvf_size_3D,\n",
    "    slice_range = mvf_slice_range,\n",
    "    \n",
    "    picked_tf = picked_tf,\n",
    "    condition_on_image = True,\n",
    "    prepare_seg = True,\n",
    "    mvf_cutoff = [-20,20],\n",
    "    augment = False,\n",
    "    augment_pre_done= augment_pre_done,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5: train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pretrained model if any\n",
    "pre_trained_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional_image:  True  condition_EF:  True  condition_seg:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch:  1\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 1.0097:   0%|          | 1/1500 [00:00<14:39,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  1.0096626281738281 average diffusion loss:  1.0096626281738281  average EF loss for factual:  0.0013932535657659173  average EF loss for counterfactual:  0.1352357566356659\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  2\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 1.0565:   0%|          | 2/1500 [00:01<14:50,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  1.0564978122711182 average diffusion loss:  1.0564978122711182  average EF loss for factual:  0.01633423939347267  average EF loss for counterfactual:  0.1374102085828781\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  3\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.6646:   0%|          | 3/1500 [00:01<13:54,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.6646173000335693 average diffusion loss:  0.6646173000335693  average EF loss for factual:  0.07123744487762451  average EF loss for counterfactual:  0.1268320530653\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  4\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.8329:   0%|          | 4/1500 [00:02<13:35,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.8329178094863892 average diffusion loss:  0.8329178094863892  average EF loss for factual:  0.048838552087545395  average EF loss for counterfactual:  0.3127792775630951\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  5\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.9047:   0%|          | 5/1500 [00:02<13:33,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.9046949148178101 average diffusion loss:  0.9046949148178101  average EF loss for factual:  0.043366432189941406  average EF loss for counterfactual:  0.31793615221977234\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  6\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.4820:   0%|          | 6/1500 [00:03<13:15,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.48204296827316284 average diffusion loss:  0.48204296827316284  average EF loss for factual:  0.10319265723228455  average EF loss for counterfactual:  0.11382845044136047\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  7\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.4539:   0%|          | 7/1500 [00:03<14:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.45393040776252747 average diffusion loss:  0.45393040776252747  average EF loss for factual:  0.18206103146076202  average EF loss for counterfactual:  0.0017920746468007565\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  8\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.8582:   1%|          | 8/1500 [00:04<13:38,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.8582490682601929 average diffusion loss:  0.8582490682601929  average EF loss for factual:  0.004037504084408283  average EF loss for counterfactual:  0.022405628114938736\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  9\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.6921:   1%|          | 9/1500 [00:04<13:24,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.692130446434021 average diffusion loss:  0.692130446434021  average EF loss for factual:  0.08118289709091187  average EF loss for counterfactual:  0.0263849887996912\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  10\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.5289:   1%|          | 9/1500 [00:05<13:24,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5288728475570679 average diffusion loss:  0.5288728475570679  average EF loss for factual:  0.18977992236614227  average EF loss for counterfactual:  0.08865281939506531\n",
      "validation at step:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.5289:   1%|          | 10/1500 [00:22<2:21:56,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  0.8826918601989746  validation diffusion loss:  0.8826918601989746  validation EF loss for factual:  0.004359617363661528  validation EF loss for counterfactual:  0.10569492727518082\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  11\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.6036:   1%|          | 11/1500 [00:22<1:42:28,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.6035605669021606 average diffusion loss:  0.6035605669021606  average EF loss for factual:  0.05417240783572197  average EF loss for counterfactual:  0.0831354483962059\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  12\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.7858:   1%|          | 12/1500 [00:23<1:14:59,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.7858350276947021 average diffusion loss:  0.7858350276947021  average EF loss for factual:  0.015112066641449928  average EF loss for counterfactual:  0.10164407640695572\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  13\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.4516:   1%|          | 13/1500 [00:23<56:03,  2.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.4516294002532959 average diffusion loss:  0.4516294002532959  average EF loss for factual:  0.04537529498338699  average EF loss for counterfactual:  0.05671017989516258\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  14\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.7414:   1%|          | 14/1500 [00:24<42:50,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.7414093017578125 average diffusion loss:  0.7414093017578125  average EF loss for factual:  0.015088777989149094  average EF loss for counterfactual:  0.2918218970298767\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  15\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.5221:   1%|          | 15/1500 [00:24<33:42,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5221033096313477 average diffusion loss:  0.5221033096313477  average EF loss for factual:  0.05714167654514313  average EF loss for counterfactual:  0.00806721206754446\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  16\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.3031:   1%|          | 16/1500 [00:25<27:56,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.3030874729156494 average diffusion loss:  0.3030874729156494  average EF loss for factual:  0.08668564260005951  average EF loss for counterfactual:  0.25117528438568115\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  17\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.5049:   1%|          | 17/1500 [00:25<23:31,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5049225687980652 average diffusion loss:  0.5049225687980652  average EF loss for factual:  0.11188337206840515  average EF loss for counterfactual:  0.13713885843753815\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  18\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.5505:   1%|          | 18/1500 [00:26<19:49,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5505450367927551 average diffusion loss:  0.5505450367927551  average EF loss for factual:  0.03741660341620445  average EF loss for counterfactual:  0.21775120496749878\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  19\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.6070:   1%|▏         | 19/1500 [00:26<17:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.6070193648338318 average diffusion loss:  0.6070193648338318  average EF loss for factual:  0.12068792432546616  average EF loss for counterfactual:  0.1949847936630249\n",
      "now run on_epoch_end function\n",
      "now run on_epoch_end function\n",
      "training epoch:  20\n",
      "learning rate:  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average loss: 0.5175:   1%|▏         | 19/1500 [00:27<17:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss:  0.5174548625946045 average diffusion loss:  0.5174548625946045  average EF loss for factual:  0.18598932027816772  average EF loss for counterfactual:  0.012523302808403969\n"
     ]
    }
   ],
   "source": [
    "start_step = 0\n",
    "\n",
    "# define trainer\n",
    "trainer = edm_warp.Trainer(diffusion_model= diffusion_model, \n",
    "                            generator_train = generator_train, \n",
    "                            generator_val = generator_val,  \n",
    "                            EF_loss_weight = EF_loss_weight,\n",
    "                            train_batch_size = 2,\n",
    "                            results_folder = os.path.join(main_path,'example_data/models', trial_name, 'models'),\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train_num_steps = 1500\n",
    "trainer.train_lr = 1e-4\n",
    "trainer.train_lr_decay_every = 500\n",
    "trainer.save_models_every = 10\n",
    "trainer.validation_every = 10\n",
    "\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# apply to the images generated by the AI motion vector field
import sys 
sys.path.append('/workspace/Documents')
import os
import torch
import nibabel as nb
import numpy as np
import pandas as pd
import ast
import Diffusion_motion_field.segmentation.model as seg_model
import Diffusion_motion_field.functions_collection as ff
import Diffusion_motion_field.Build_lists.Build_list as Build_list
import Diffusion_motion_field.segmentation.Generator as Generator

main_path = '/mnt/camca_NAS/4DCT'
timeframe_info = pd.read_excel('/mnt/camca_NAS/4DCT/Patient_lists/uc/patient_list_final_selection_timeframes.xlsx')

####################### 
trial_name = 'seg_3D'
num_classes = 4 # 4 classes: background, LV, LA, LVOT

epoch = 352
trained_model_filename = os.path.join(main_path, 'models', trial_name, 'models/model-' + str(epoch)+ '.pt')
save_folder = os.path.join(main_path, 'models', trial_name, 'pred_seg'); os.makedirs(save_folder, exist_ok=True)

img_size_3D = [160,160,96]
#######################
# # define train
data_sheet = os.path.join(main_path,'Patient_lists/uc/patient_list_MVF_diffusion_train_test_filtered_at_least_10tf.xlsx')
# data_sheet = os.path.join(main_path,'Patient_lists/mgh/patient_list_MVF_diffusion_train_test.xlsx')
b = Build_list.Build(data_sheet)
patient_class_list, patient_id_list,_ = b.__build__(batch_list = [5])
patient_class_list = patient_class_list[-20:]
patient_id_list = patient_id_list[-20:]

# build model
model = seg_model.Unet3D(
    init_dim = 16,
    channels = 1,
    num_classes = num_classes,
    dim_mults = (2,4,8,16),
    full_attn = (None,None, None, None),
    act = 'LeakyReLU',)

study_name = 'MVF_EDM_down_10tf_imgcon_EFcon_EFpredict'
epoch = 1077
how_many_time_frames = 10 if '10tf' in study_name else 5

# main
results = []
for i in range(0,5):##patient_class_list.shape[0]):
    
    patient_class = patient_class_list[i]
    patient_id = patient_id_list[i]

    print(patient_class, patient_id)

    # patient folder
    save_folder = os.path.join(main_path, 'models', study_name, 'pred_mvf', patient_class, patient_id)
    save_folder_sub_list = ff.find_all_target_files(['epoch'+str(epoch) +'*'], save_folder)
    print(save_folder, save_folder_sub_list )

    # get the ES frame
    row = timeframe_info[timeframe_info['patient_id'] == patient_id]
    es_index = row['es_index'].iloc[0]
    sampled_time_frame_list = ast.literal_eval(row['sampled_time_frame_list'].iloc[0])
    normalized_time_frame_list = ast.literal_eval(row['normalized_time_frame_list_copy'].iloc[0])

    picked_tf_normalized = [0.1,0.3,0.5,0.7,0.9] if how_many_time_frames == 5 else [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
    picked_tf = [sampled_time_frame_list[normalized_time_frame_list.index(picked_tf_normalized[iii])] for iii in range(0,len(picked_tf_normalized))]   

    # original EF
    EF_original = row['EF_sampled_in_10tf'].iloc[0] * 100 if how_many_time_frames == 10 else row['EF_sampled_in_5tf'].iloc[0] * 100
  
    for ss in range(0, save_folder_sub_list.shape[0]):
        save_folder_sub = save_folder_sub_list[ss]
        print('current folder:', save_folder_sub)
        # EF_set = int(save_folder_sub.split('EF')[-1])

        time_frame_list =[0] + picked_tf# [0,es_index]

        if os.path.isfile(os.path.join(save_folder_sub, 'seg_tf'+str(time_frame_list[-1])+'.nii.gz')) == 0:

            for tf in time_frame_list:
                if tf == 0:
                    defined_input_path = os.path.join(save_folder_sub, 'template_img.nii.gz')
                else:
                    defined_input_path = os.path.join(save_folder_sub, 'warped_img_pred_tf'+str(tf)+'.nii.gz')

                generator = Generator.Dataset_3D(
                    np.asarray([patient_class]),
                    np.asarray([patient_id]),
                    image_folder = '/mnt/camca_NAS/4DCT/',
                    img_size_3D = img_size_3D,
                    picked_tf = tf, #'random' or specific tf or 'ES'
                    defined_input_path = defined_input_path,
                    relabel_LVOT = True,)
                
                sampler = seg_model.Sampler(
                    model,
                    generator,
                    image_size = img_size_3D,
                    batch_size = 1)

                save_file = os.path.join(save_folder_sub, 'seg_tf' + str(tf) + '.nii.gz')
                sampler.sample(trained_model_filename, save_file, patient_class, patient_id, picked_tf = tf, save_gt_and_img = False)

            # we now calculate the EF from AI image
        segs = np.zeros((len(time_frame_list), img_size_3D[0], img_size_3D[1], img_size_3D[2]))
        lv_list = []
        for k in range(len(time_frame_list)):
            segs[k] = nb.load(os.path.join(save_folder_sub, 'seg_tf'+str(time_frame_list[k])+'.nii.gz')).get_fdata()
            lv_list.append(np.sum(segs[k] == 1))
        lv_list = np.asarray(lv_list)
        EF_AI = (lv_list[0] - np.min(lv_list[1:])) / lv_list[0] * 100

        with open(os.path.join(save_folder_sub,'EF.txt'), "r") as f:
            content = f.read()
        EF_set = float(content) * 100
      
        print('EF EF set and EF AI: ',  EF_set, EF_AI)

        results.append([patient_class, patient_id, ss, EF_original, EF_set, EF_AI])
        df = pd.DataFrame(results, columns = ['patient_class', 'patient_id', 'sample', 'EF_original', 'EF_set', 'EF_AI'])
        df.to_excel(os.path.join(main_path, 'models', study_name, 'EF_seg_results_epoch' + str(epoch) + '.xlsx'), index = False)


# df = pd.read_excel(os.path.join('/mnt/camca_NAS/4DCT/models/MVF_EDM_latent_5tf_imgcon_EFcon_trial2/EF_results_epoch2940.xlsx'))

# data_sheet = os.path.join(os.path.dirname(main_path),'Patient_lists/patient_list_MVF_diffusion_train_test_filtered_at_least_10tf.xlsx')
# b = Build_list.Build(data_sheet)
# patient_class_list, patient_id_list,_ = b.__build__(batch_list = [5])
# patient_class_list = patient_class_list[-20:]
# patient_id_list = patient_id_list[-20:]

# range_list = []
# for patient_id in patient_id_list:
#     row = df[df['patient_id'] == patient_id]
#     EF_list = []
#     for i in range(0, len(row)):
#         EF_list.append(row['EF_AI'].iloc[i])
#     EF_list = np.array(EF_list)
#     print(np.max(EF_list) - np.min(EF_list), np.std(EF_list))
#     range_list.append(np.max(EF_list) - np.min(EF_list))
# print(np.mean(range_list), np.std(range_list))





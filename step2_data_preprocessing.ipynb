{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps\n",
    "\n",
    "In this script, we perform the following preprocessing tasks:\n",
    "\n",
    "1. Prepare the **left ventricular (LV) segmentation masks** using pre-trained network.\n",
    "2. Sample the original time frames into **10 evenly spaced cardiac phases** and Get ground truth Ejection fraction (LVEF) for each case.\n",
    "3. Prepare augmented data for training (since data is large, on-the-fly augmentation will be time-consuming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import Cardiac4DCT_Synth_Diffusion.Build_lists.Build_list as Build_list\n",
    "import Cardiac4DCT_Synth_Diffusion.functions_collection as ff\n",
    "import Cardiac4DCT_Synth_Diffusion.Data_processing as Data_processing\n",
    "\n",
    "main_path = '/mnt/camca_NAS/4DCT' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Prepare LV segmentation masks using pre-trained segmentation network\n",
    "this mask will be used for our mapping funciton during diffusion model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import Cardiac4DCT_Synth_Diffusion.segmentation_network.Generator as Generator\n",
    "import Cardiac4DCT_Synth_Diffusion.segmentation_network.model as seg_model\n",
    "save_folder = os.path.join(main_path,'example_data/predicted_seg')\n",
    "ff.make_folder([save_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pre-trained segmentation model and the patient list\n",
    "trained_model_filename = os.path.join(main_path, 'models', 'seg_3D', 'models/model-352.pt')\n",
    "\n",
    "data_sheet = os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list.xlsx')\n",
    "b = Build_list.Build(data_sheet)\n",
    "patient_class_list, patient_id_list,_ = b.__build__(batch_list = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in out is :  [(16, 32), (32, 64), (64, 128), (128, 256)]\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = seg_model.Unet3D(\n",
    "    init_dim = 16,\n",
    "    channels = 1,\n",
    "    num_classes = 4, #4 classes: background, LV, LA, LVOT\n",
    "    dim_mults = (2,4,8,16),\n",
    "    full_attn = (None,None, None, None),\n",
    "    act = 'LeakyReLU',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_data example_1\n",
      "num of tf: 20\n",
      "generating segmentation for tf: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Documents/Cardiac4DCT_Synth_Diffusion/segmentation_network/model.py:794: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(trained_model_filename, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating segmentation for tf: 1\n",
      "generating segmentation for tf: 2\n",
      "generating segmentation for tf: 3\n",
      "generating segmentation for tf: 4\n",
      "generating segmentation for tf: 5\n",
      "generating segmentation for tf: 6\n",
      "generating segmentation for tf: 7\n",
      "generating segmentation for tf: 8\n",
      "generating segmentation for tf: 9\n",
      "generating segmentation for tf: 10\n",
      "generating segmentation for tf: 11\n",
      "generating segmentation for tf: 12\n",
      "generating segmentation for tf: 13\n",
      "generating segmentation for tf: 14\n",
      "generating segmentation for tf: 15\n",
      "generating segmentation for tf: 16\n",
      "generating segmentation for tf: 17\n",
      "generating segmentation for tf: 18\n",
      "generating segmentation for tf: 19\n",
      "example_data example_2\n",
      "num of tf: 20\n",
      "generating segmentation for tf: 0\n",
      "generating segmentation for tf: 1\n",
      "generating segmentation for tf: 2\n",
      "generating segmentation for tf: 3\n",
      "generating segmentation for tf: 4\n",
      "generating segmentation for tf: 5\n",
      "generating segmentation for tf: 6\n",
      "generating segmentation for tf: 7\n",
      "generating segmentation for tf: 8\n",
      "generating segmentation for tf: 9\n",
      "generating segmentation for tf: 10\n",
      "generating segmentation for tf: 11\n",
      "generating segmentation for tf: 12\n",
      "generating segmentation for tf: 13\n",
      "generating segmentation for tf: 14\n",
      "generating segmentation for tf: 15\n",
      "generating segmentation for tf: 16\n",
      "generating segmentation for tf: 17\n",
      "generating segmentation for tf: 18\n",
      "generating segmentation for tf: 19\n"
     ]
    }
   ],
   "source": [
    "# generate segmentation\n",
    "for i in range(0,patient_class_list.shape[0]):\n",
    "    \n",
    "    patient_class = patient_class_list[i]\n",
    "    patient_id = patient_id_list[i]\n",
    "\n",
    "    print(patient_class, patient_id)\n",
    "\n",
    "    # get the number of time frames\n",
    "    files = ff.find_all_target_files(['*.nii.gz'],os.path.join(main_path,'example_data','nii-images',patient_class, patient_id, 'img-nii-resampled-1.5mm'))\n",
    "    tf_num = len(files)\n",
    "    print('num of tf:', tf_num)\n",
    "\n",
    "    save_folder_case = os.path.join(save_folder,patient_class, patient_id)\n",
    "    ff.make_folder([os.path.join(save_folder, patient_class), os.path.join(save_folder, patient_class, patient_id)])\n",
    "\n",
    "    for tf in range(0,tf_num):\n",
    "        print('generating segmentation for tf:', tf)\n",
    "\n",
    "        save_folder_case = os.path.join(save_folder,patient_class, patient_id)\n",
    "        save_file = os.path.join(save_folder_case, 'pred_s_' + str(tf) + '.nii.gz')\n",
    "\n",
    "        if os.path.isfile(save_file) == False:\n",
    "            generator = Generator.Dataset_3D(\n",
    "                np.asarray([patient_class]),\n",
    "                np.asarray([patient_id]),\n",
    "                image_folder = os.path.join(main_path,'example_data'),\n",
    "                have_manual_seg = False,\n",
    "                img_size_3D = [160,160,96], # default\n",
    "                picked_tf = tf, #'random' or specific tf \n",
    "                )\n",
    "\n",
    "            # sample:\n",
    "            sampler = seg_model.Sampler(\n",
    "                model,\n",
    "                generator,\n",
    "                image_size = [160,160,96], # default\n",
    "                batch_size = 1)\n",
    "\n",
    "            sampler.sample(trained_model_filename, save_file, patient_class, patient_id, picked_tf = tf, reshape_pred = True, save_gt_and_img=False, main_folder = '/mnt/camca_NAS/4DCT/example_data')\n",
    "\n",
    "            # do postprocessing if needed (remove scatter)\n",
    "            original_a = nb.load(save_file).get_fdata(); original_a = np.round(original_a).astype(int)\n",
    "            a = np.copy(original_a)\n",
    "            a[a != 1] = 0\n",
    "            if np.sum(a) == 0:\n",
    "                new_image = original_a\n",
    "            else:\n",
    "                new_image,need_to_remove = ff.remove_scatter3D(a,1)\n",
    "                # print('need to remove:',need_to_remove)\n",
    "                new_image[original_a == 2] = 2; new_image[original_a == 3] = 3\n",
    "                nb.save(nb.Nifti1Image(new_image, nb.load(save_file).affine, nb.load(save_file).header), save_file)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Sample 10 time frames and get EF\n",
    "\n",
    "the results will be saved into a spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_class: example_data  patient_id: example_1\n",
      "patient_class: example_data  patient_id: example_2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_EDM_warp as warp_func\n",
    "\n",
    "spreadsheet = pd.read_excel(os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list.xlsx'))\n",
    "results = []\n",
    "for i in range(0,spreadsheet.shape[0]):\n",
    "    patient_class = spreadsheet.iloc[i]['patient_class']\n",
    "    patient_id = spreadsheet.iloc[i]['patient_id']\n",
    "   \n",
    "    print('patient_class:', patient_class, ' patient_id:', patient_id)\n",
    "\n",
    "    # load segmentation\n",
    "    seg_folder = os.path.join(main_path,'example_data/predicted_seg/',patient_class,patient_id)\n",
    "    seg_files = ff.sort_timeframe(ff.find_all_target_files(['*.nii.gz'],seg_folder),2,'_')\n",
    "    total_tf_num = len(seg_files)\n",
    "    \n",
    "    seg_volumes = []\n",
    "    for ii in range(0, seg_files.shape[0]):\n",
    "        img = nb.load(seg_files[ii]).get_fdata(); img = np.round(img).astype(np.uint8)\n",
    "        seg_volumes.append(img)\n",
    "    seg_volumes = np.transpose(np.asarray(seg_volumes),(1,2,3,0))\n",
    "\n",
    "    # get a list of LV volumes (pixel value = 1) for all timeframes\n",
    "    LV_volume_list = [np.sum(seg_volumes[:,:,:,i]==1) for i in range(0,seg_volumes.shape[-1])]\n",
    "    LV_volume_list = np.asarray(LV_volume_list)\n",
    "\n",
    "    # get ES time frame\n",
    "    es_index = np.where(np.array(LV_volume_list) == np.min(LV_volume_list))[0][0]\n",
    "    # ejection_fraction = (LV_volume_list[0] - LV_volume_list[es_index])/LV_volume_list[0]\n",
    "    # last_tf_percent = (LV_volume_list[0] - LV_volume_list[-1])/LV_volume_list[0]\n",
    "\n",
    "    # turn the time frame list into [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] --> sample 10 time frames evenly\n",
    "\n",
    "    # sample the temporal series\n",
    "    normalized_time_frame_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]; normalized_time_frame_list_copy = normalized_time_frame_list.copy()\n",
    "    sampled_time_frame_list = []\n",
    "    for t in range(0,len(normalized_time_frame_list)):\n",
    "        # find the closest time frame to the normalized time frame\n",
    "        tf_index = int(round(normalized_time_frame_list[t]*total_tf_num))\n",
    "        if tf_index >= total_tf_num:\n",
    "            tf_index = total_tf_num - 1\n",
    "        sampled_time_frame_list.append(tf_index)\n",
    "\n",
    "    # also calculate if pick 10 time frames, the ejection fraction is?\n",
    "    # calculate the ejection fraction using segmentation at ED 0 and applying deformation field at each time frame --> don't just use the EF from segmentation, this EF from deformation field will be used in the model training\n",
    "    picked_tf_normalized = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    if len(sampled_time_frame_list)< 10:\n",
    "        ejection_fraction_picked_10tf_from_mvf = ''\n",
    "    else:\n",
    "        picked_tf = [sampled_time_frame_list[normalized_time_frame_list.index(picked_tf_normalized[iii])] for iii in range(0,len(picked_tf_normalized))]\n",
    "        seg_template = nb.load(os.path.join(seg_folder, 'pred_s_0.nii.gz')).get_fdata()\n",
    "        seg_template = np.round(seg_template).astype(np.int16)  \n",
    "        seg_template[seg_template != 1] = 0\n",
    "        seg_template = Data_processing.crop_or_pad(seg_template, [160,160,96], value = 0)\n",
    "\n",
    "        mvf_folder = os.path.join(main_path,'example_data/mvf_warp0_onecase/',patient_class, patient_id, 'voxel_final')\n",
    "        volume_list = []\n",
    "        volume_list = []\n",
    "        seg_template_torch = torch.from_numpy(seg_template).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "        for tf_n in range(0,len(picked_tf)):\n",
    "            mvf_file = os.path.join(mvf_folder, str(picked_tf[tf_n]) + '.nii.gz')\n",
    "            mvf_data = nb.load(mvf_file).get_fdata()\n",
    "            mvf_data_torch = torch.from_numpy(np.transpose(mvf_data, (3, 0, 1, 2))).unsqueeze(0).float().cuda()\n",
    "            warped_seg = warp_func.warp_segmentation_from_mvf(seg_template_torch, mvf_data_torch)\n",
    "            warped_seg = warped_seg.squeeze(0).squeeze(0).cpu().numpy()\n",
    "            volume_list.append(np.sum(warped_seg))\n",
    "        # print('volume_list: ', volume_list)\n",
    "        volume_list = np.asarray(volume_list)\n",
    "        ejection_fraction_picked_10tf_from_mvf = (LV_volume_list[0] - np.min(volume_list))/LV_volume_list[0]\n",
    "\n",
    "    LV_volume_list = LV_volume_list.tolist()\n",
    "\n",
    "    # # append the results to the results list\n",
    "    results.append([patient_class, patient_id, total_tf_num, es_index,  sampled_time_frame_list, normalized_time_frame_list_copy, LV_volume_list, ejection_fraction_picked_10tf_from_mvf])\n",
    "\n",
    "    df = pd.DataFrame(results, columns = ['patient_class', 'patient_id', 'total_tf_num', 'es_index','sampled_time_frame_list', 'normalized_time_frame_list_copy', 'LV_volume_list',   'EF_sampled_in_10tf_by_mvf'])\n",
    "    df.to_excel(os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list_final_selection_timeframes.xlsx'), index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Prepare augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import ndimage\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "timeframe_info = pd.read_excel(os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list_final_selection_timeframes.xlsx'))\n",
    "\n",
    "# define the patient list\n",
    "data_sheet = os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list.xlsx')\n",
    "b = Build_list.Build(data_sheet)\n",
    "patient_class_list, patient_id_list,_ = b.__build__(batch_list = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 patient_class: example_data patient_id: example_1\n",
      "time_frame_list: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "aug_index: 0\n",
      "load aug_parameter from file\n",
      "z_rotate_degree: 0 x_translate: 0 y_translate: 0\n",
      "current time frame:  0  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/0.nii.gz\n",
      "current time frame:  2  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/2.nii.gz\n",
      "current time frame:  4  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/4.nii.gz\n",
      "current time frame:  6  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/6.nii.gz\n",
      "current time frame:  8  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/8.nii.gz\n",
      "current time frame:  10  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/10.nii.gz\n",
      "current time frame:  12  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/12.nii.gz\n",
      "current time frame:  14  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/14.nii.gz\n",
      "current time frame:  16  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/16.nii.gz\n",
      "current time frame:  18  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/18.nii.gz\n",
      "condition image file exists: /mnt/camca_NAS/4DCT/example_data/mvf_aug/example_data/example_1/aug_0/condition_img/0.nii.gz\n",
      "segmentation file exists: /mnt/camca_NAS/4DCT/example_data/mvf_aug/example_data/example_1/aug_0/segmentation/0.nii.gz\n",
      "aug_index: 1\n",
      "z_rotate_degree: 4.129243844695559 x_translate: 14 y_translate: -15\n",
      "current time frame:  0  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/0.nii.gz\n",
      "current time frame:  2  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/2.nii.gz\n",
      "current time frame:  4  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/4.nii.gz\n",
      "current time frame:  6  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/6.nii.gz\n",
      "current time frame:  8  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/8.nii.gz\n",
      "current time frame:  10  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/10.nii.gz\n",
      "current time frame:  12  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/12.nii.gz\n",
      "current time frame:  14  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/14.nii.gz\n",
      "current time frame:  16  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/16.nii.gz\n",
      "current time frame:  18  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/18.nii.gz\n",
      "aug_index: 2\n",
      "z_rotate_degree: -11.41270390816346 x_translate: -1 y_translate: -8\n",
      "current time frame:  0  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/0.nii.gz\n",
      "current time frame:  2  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/2.nii.gz\n",
      "current time frame:  4  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/4.nii.gz\n",
      "current time frame:  6  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/6.nii.gz\n",
      "current time frame:  8  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/8.nii.gz\n",
      "current time frame:  10  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/10.nii.gz\n",
      "current time frame:  12  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/12.nii.gz\n",
      "current time frame:  14  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/14.nii.gz\n",
      "current time frame:  16  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/16.nii.gz\n",
      "current time frame:  18  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_1/voxel_final/18.nii.gz\n",
      "i: 1 patient_class: example_data patient_id: example_2\n",
      "time_frame_list: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "aug_index: 0\n",
      "z_rotate_degree: 0 x_translate: 0 y_translate: 0\n",
      "current time frame:  0  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/0.nii.gz\n",
      "current time frame:  2  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/2.nii.gz\n",
      "current time frame:  4  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/4.nii.gz\n",
      "current time frame:  6  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/6.nii.gz\n",
      "current time frame:  8  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/8.nii.gz\n",
      "current time frame:  10  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/10.nii.gz\n",
      "current time frame:  12  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/12.nii.gz\n",
      "current time frame:  14  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/14.nii.gz\n",
      "current time frame:  16  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/16.nii.gz\n",
      "current time frame:  18  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/18.nii.gz\n",
      "aug_index: 1\n",
      "z_rotate_degree: 4.951695783990516 x_translate: 12 y_translate: 6\n",
      "current time frame:  0  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/0.nii.gz\n",
      "current time frame:  2  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/2.nii.gz\n",
      "current time frame:  4  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/4.nii.gz\n",
      "current time frame:  6  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/6.nii.gz\n",
      "current time frame:  8  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/8.nii.gz\n",
      "current time frame:  10  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/10.nii.gz\n",
      "current time frame:  12  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/12.nii.gz\n",
      "current time frame:  14  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/14.nii.gz\n",
      "current time frame:  16  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/16.nii.gz\n",
      "current time frame:  18  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/18.nii.gz\n",
      "aug_index: 2\n",
      "z_rotate_degree: 5.570084878913832 x_translate: -12 y_translate: 15\n",
      "current time frame:  0  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/0.nii.gz\n",
      "current time frame:  2  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/2.nii.gz\n",
      "current time frame:  4  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/4.nii.gz\n",
      "current time frame:  6  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/6.nii.gz\n",
      "current time frame:  8  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/8.nii.gz\n",
      "current time frame:  10  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/10.nii.gz\n",
      "current time frame:  12  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/12.nii.gz\n",
      "current time frame:  14  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/14.nii.gz\n",
      "current time frame:  16  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/16.nii.gz\n",
      "current time frame:  18  file: /mnt/camca_NAS/4DCT/example_data/mvf_warp0_onecase/example_data/example_2/voxel_final/18.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# do augmentation, 3 augmentation for each case\n",
    "for i in range(0, patient_id_list.shape[0]):\n",
    "    patient_class = patient_class_list[i]\n",
    "    patient_id = patient_id_list[i]\n",
    "  \n",
    "    print('i:', i, 'patient_class:', patient_class, 'patient_id:', patient_id)\n",
    "\n",
    "    # save folder \n",
    "    save_folder = os.path.join(main_path,'example_data/mvf_aug/', patient_class, patient_id)\n",
    "    ff.make_folder([os.path.join(main_path,'example_data/mvf_aug'), os.path.join(main_path,'example_data/mvf_aug', patient_class), os.path.join(main_path,'example_data/mvf_aug', patient_class, patient_id)])\n",
    "\n",
    "    # load the original MVF\n",
    "    path = os.path.join(main_path, 'example_data/mvf_warp0_onecase',patient_class,patient_id,'voxel_final')\n",
    "    files = ff.find_all_target_files(['*.nii.gz'],path)\n",
    "    final_files = np.copy(files)\n",
    "    for f in files:\n",
    "        if 'moved' in f or 'original' in f:\n",
    "            # remove it from the numpy array\n",
    "            final_files = np.delete(final_files, np.where(final_files == f))\n",
    "    files = ff.sort_timeframe(final_files,2)\n",
    "\n",
    "    # get time frames\n",
    "    row = timeframe_info[timeframe_info['patient_id'] == patient_id]\n",
    "    sampled_time_frame_list = ast.literal_eval(row['sampled_time_frame_list'].iloc[0])\n",
    "    print('time_frame_list:', sampled_time_frame_list)\n",
    "\n",
    "    for aug_index in range(0,3):\n",
    "        print('aug_index:', aug_index)\n",
    "        # set augmentation parameters\n",
    "        if os.path.isfile(os.path.join(save_folder, 'aug_'+str(aug_index), 'aug_parameter.npy')):\n",
    "            print('load aug_parameter from file')\n",
    "            aug_parameter = np.load(os.path.join(save_folder, 'aug_'+str(aug_index), 'aug_parameter.npy'))\n",
    "            z_rotate_degree = aug_parameter[0]\n",
    "            x_translate = int(aug_parameter[1])\n",
    "            y_translate = int(aug_parameter[2])\n",
    "        else:\n",
    "            z_rotate_degree = random.uniform(-15,15) if aug_index != 0 else 0\n",
    "            x_translate = int(round(random.uniform(-15,15))) if aug_index != 0 else 0\n",
    "            y_translate = int(round(random.uniform(-15,15))) if aug_index != 0 else 0\n",
    "            aug_parameter = [z_rotate_degree, x_translate, y_translate] if aug_index != 0 else [0,0,0]\n",
    "            save_folder_aug = os.path.join(save_folder, 'aug_'+str(aug_index)); ff.make_folder([save_folder_aug])\n",
    "            np.save(os.path.join(save_folder_aug, 'aug_parameter.npy'), np.asarray(aug_parameter))\n",
    "        print('z_rotate_degree:', z_rotate_degree, 'x_translate:', x_translate, 'y_translate:', y_translate)\n",
    "        \n",
    "        ######## load each MVF and do augmentation as well as latent encoding\n",
    "        for j in range(0,len(sampled_time_frame_list)):\n",
    "            \n",
    "            j = sampled_time_frame_list[j]\n",
    "            print('current time frame: ', j , ' file:', files[j])\n",
    "            \n",
    "            ##### aug_index = 0, just copy the original MVF\n",
    "            if aug_index == 0:\n",
    "                ff.make_folder([os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf'), os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf_downsampled')])\n",
    "                mvf = nb.load(files[j]).get_fdata()\n",
    "                downsample_mvf = block_reduce(np.copy(mvf), (4,4,4,1), func=np.mean)\n",
    "                affine = nb.load(files[j]).affine\n",
    "                nb.save(nb.Nifti1Image(downsample_mvf, affine), os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf_downsampled', str(j)+'.nii.gz'))\n",
    "                continue\n",
    "       \n",
    "            ###### MVF\n",
    "            if os.path.isfile(os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf', str(j)+'.nii.gz')):\n",
    "                print('Aug mvf file exists:', os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf', str(j)+'.nii.gz'))\n",
    "                mvf_aug = nb.load(os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf', str(j)+'.nii.gz'))\n",
    "                affine = mvf_aug.affine\n",
    "                mvf_aug = mvf_aug.get_fdata()\n",
    "            else:\n",
    "                mvf = nb.load(files[j]).get_fdata()\n",
    "                affine = nb.load(files[j]).affine\n",
    "                mvf_aug = Data_processing.random_move(mvf,x_translate,y_translate,z_rotate_degree, fill_val=0, do_augment=True)\n",
    "                # print('mvf aug shape:', mvf_aug.shape)\n",
    "\n",
    "                # save the augmented MVF\n",
    "                save_folder_aug = os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf'); ff.make_folder([os.path.dirname(save_folder_aug),save_folder_aug])\n",
    "                save_path = os.path.join(save_folder_aug, str(j)+'.nii.gz')\n",
    "                img = nb.Nifti1Image(mvf_aug, affine)\n",
    "                nb.save(img, save_path)\n",
    "\n",
    "            ###### downsample MVF:\n",
    "            if os.path.isfile(os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf_downsampled', str(j)+'.nii.gz'))==1:\n",
    "                print('Aug downsampled mvf file exists:', os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf_downsampled', str(j)+'.nii.gz'))\n",
    "            else:\n",
    "                downsample_mvf_aug =  block_reduce(np.copy(mvf_aug), (4,4,4,1), func=np.mean)\n",
    "                save_folder_aug_downsample = os.path.join(save_folder, 'aug_'+str(aug_index), 'mvf_downsampled'); ff.make_folder([os.path.dirname(save_folder_aug_downsample),save_folder_aug_downsample])\n",
    "                save_path = os.path.join(save_folder_aug_downsample, str(j)+'.nii.gz')\n",
    "                nb.save( nb.Nifti1Image(downsample_mvf_aug, affine), save_path)\n",
    "        \n",
    "\n",
    "        # augment for condition image as well\n",
    "        if os.path.isfile(os.path.join(save_folder, 'aug_'+str(aug_index), 'condition_img', '0.nii.gz')):\n",
    "            print('condition image file exists:', os.path.join(save_folder, 'aug_'+str(aug_index), 'condition_img', '0.nii.gz'))\n",
    "        else:\n",
    "            img_path = os.path.join(main_path, 'example_data/nii-images', patient_class, patient_id, 'img-nii-resampled-1.5mm/0.nii.gz')\n",
    "        \n",
    "            con_img = nb.load(img_path).get_fdata()\n",
    "            affine = nb.load(img_path).affine\n",
    "            if len(con_img.shape) == 4:\n",
    "                con_img = con_img[:,:,:,0]\n",
    "            con_img = Data_processing.crop_or_pad(con_img, [160,160,96], value = np.min(con_img))\n",
    "\n",
    "            con_img1 = np.copy(con_img)\n",
    "            con_img1 = Data_processing.random_move(con_img1,x_translate,y_translate,z_rotate_degree,do_augment = True, fill_val = np.min(con_img))\n",
    "            con_img1 = block_reduce(con_img1, (160//40,160//40, 96//24), func=np.mean)\n",
    "\n",
    "            save_folder_aug = os.path.join(save_folder, 'aug_'+str(aug_index), 'condition_img'); ff.make_folder([os.path.dirname(save_folder_aug),save_folder_aug])\n",
    "            nb.save(nb.Nifti1Image(con_img1, affine), os.path.join(save_folder_aug, '0.nii.gz'))\n",
    "\n",
    "        # augment for segmentation as well\n",
    "        if os.path.isfile(os.path.join(save_folder, 'aug_'+str(aug_index), 'segmentation', '0.nii.gz')) and os.path.isfile(os.path.join(save_folder, 'aug_'+str(aug_index), 'segmentation_original_res', '0.nii.gz')):\n",
    "            print('segmentation file exists:', os.path.join(save_folder, 'aug_'+str(aug_index), 'segmentation', '0.nii.gz'))\n",
    "        else:\n",
    "            seg_path = os.path.join(main_path,'example_data/predicted_seg', patient_class, patient_id,'pred_s_0.nii.gz')\n",
    "            # seg_path = os.path.join('/mnt/camca_NAS/4DCT/mgh_data/predicted_seg', patient_class, patient_id,'pred_s_0.nii.gz')\n",
    "            seg_img = nb.load(seg_path).get_fdata(); seg_img = np.round(seg_img).astype(np.int16)\n",
    "            affine = nb.load(seg_path).affine\n",
    "            if len(seg_img.shape) == 4:\n",
    "                seg_img = seg_img[:,:,:,0]\n",
    "            # make it binary\n",
    "            seg_img[seg_img != 1] = 0\n",
    "            # crop\n",
    "            seg_img = Data_processing.crop_or_pad(seg_img, [160,160,96], value = 0)\n",
    "            # augmentation\n",
    "            seg_img1 = np.copy(seg_img)\n",
    "            seg_img1 = Data_processing.random_move(seg_img1,x_translate,y_translate,z_rotate_degree,do_augment = True, fill_val = 0, order = 0)\n",
    "            save_folder_aug = os.path.join(save_folder, 'aug_'+str(aug_index), 'segmentation_original_res'); ff.make_folder([os.path.dirname(save_folder_aug),save_folder_aug])\n",
    "            nb.save(nb.Nifti1Image(seg_img1, affine), os.path.join(save_folder, 'aug_'+str(aug_index), 'segmentation_original_res', '0.nii.gz'))\n",
    "            seg_img1 = block_reduce(seg_img1, (160//40,160//40, 96//24), func=np.max)\n",
    "            save_folder_aug = os.path.join(save_folder, 'aug_'+str(aug_index), 'segmentation'); ff.make_folder([os.path.dirname(save_folder_aug),save_folder_aug])\n",
    "            nb.save(nb.Nifti1Image(seg_img1, affine), os.path.join(save_folder_aug, '0.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

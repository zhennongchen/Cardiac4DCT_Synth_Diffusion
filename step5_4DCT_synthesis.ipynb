{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "In this script, we use ***synthesized MVFs*** and ***3DCT template*** to generate 4DCT sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "\n",
    "# third party imports\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import nibabel as nb\n",
    "import ast\n",
    "from skimage.measure import block_reduce\n",
    "from scipy.ndimage import zoom\n",
    "import Cardiac4DCT_Synth_Diffusion.Build_lists.Build_list as Build_list\n",
    "import Cardiac4DCT_Synth_Diffusion.functions_collection as ff\n",
    "import Cardiac4DCT_Synth_Diffusion.Data_processing as Data_processing\n",
    "import Cardiac4DCT_Synth_Diffusion.denoising_diffusion_pytorch.denoising_diffusion_pytorch.conditional_EDM_warp as warp_func\n",
    "\n",
    "main_path = '/mnt/camca_NAS/4DCT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe_info = pd.read_excel(os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list_final_selection_timeframes.xlsx'))\n",
    "\n",
    "trial_name = 'MVF_EDM'\n",
    "\n",
    "save_path = os.path.join(main_path, 'example_data/models', trial_name, 'pred_mvf')\n",
    "\n",
    "# # define training and validation data\n",
    "data_sheet = os.path.join(main_path,'example_data/Patient_lists/example_data/patient_list.xlsx')\n",
    "\n",
    "b = Build_list.Build(data_sheet)\n",
    "patient_class_list, patient_id_list,_ = b.__build__(batch_list = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 example_data example_1\n",
      "picked tf: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "save_folder : /mnt/camca_NAS/4DCT/example_data/models/MVF_EDM/pred_mvf/example_data/example_1\n",
      "current folder: /mnt/camca_NAS/4DCT/example_data/models/MVF_EDM/pred_mvf/example_data/example_1/test_0\n",
      "current folder: /mnt/camca_NAS/4DCT/example_data/models/MVF_EDM/pred_mvf/example_data/example_1/test_1\n",
      "1 example_data example_2\n",
      "picked tf: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "save_folder : /mnt/camca_NAS/4DCT/example_data/models/MVF_EDM/pred_mvf/example_data/example_2\n",
      "current folder: /mnt/camca_NAS/4DCT/example_data/models/MVF_EDM/pred_mvf/example_data/example_2/test_0\n",
      "current folder: /mnt/camca_NAS/4DCT/example_data/models/MVF_EDM/pred_mvf/example_data/example_2/test_1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,patient_class_list.shape[0]):\n",
    "    \n",
    "    patient_class = patient_class_list[i]\n",
    "    patient_id = patient_id_list[i]\n",
    "    print(i, patient_class, patient_id)\n",
    "\n",
    "    img_path = os.path.join(main_path,'example_data/nii-images' ,patient_class, patient_id,'img-nii-resampled-1.5mm')\n",
    "    save_folder = os.path.join(save_path, patient_class, patient_id)\n",
    "    ff.make_folder([os.path.dirname(save_folder), save_folder])\n",
    "\n",
    "    tf_files = ff.sort_timeframe(ff.find_all_target_files(['*.nii.gz'],img_path),2)\n",
    "    template_image = nb.load(tf_files[0]).get_fdata()\n",
    "    if len(template_image.shape) == 4:\n",
    "        template_image = template_image[:,:,:,0]\n",
    "    template_image = Data_processing.crop_or_pad(template_image, [160,160,96], value = np.min(template_image))\n",
    "    affine = nb.load(tf_files[0]).affine\n",
    "\n",
    "    row = timeframe_info[timeframe_info['patient_id'] == patient_id]\n",
    "    sampled_time_frame_list = ast.literal_eval(row['sampled_time_frame_list'].iloc[0])\n",
    "    normalized_time_frame_list = ast.literal_eval(row['normalized_time_frame_list_copy'].iloc[0])\n",
    "\n",
    "    picked_tf_normalized = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    picked_tf = [sampled_time_frame_list[normalized_time_frame_list.index(picked_tf_normalized[iii])] for iii in range(0,len(picked_tf_normalized))]   \n",
    "    print('picked tf:' ,picked_tf)\n",
    "\n",
    "    save_folder_sub_list = ff.find_all_target_files(['*'],save_folder)\n",
    "\n",
    "    for ss in range(0, save_folder_sub_list.shape[0]):\n",
    "        save_folder_sub = save_folder_sub_list[ss]\n",
    "        print('current folder:', save_folder_sub)\n",
    "        nb.save(nb.Nifti1Image(template_image, affine), os.path.join(save_folder_sub, 'template_img.nii.gz'))\n",
    "        \n",
    "    \n",
    "        for tf in picked_tf:\n",
    "            warped_img_gt = nb.load(tf_files[tf]).get_fdata()\n",
    "            if len(warped_img_gt.shape) == 4:\n",
    "                warped_img_gt = warped_img_gt[:,:,:,0]\n",
    "            warped_img_gt = Data_processing.crop_or_pad(warped_img_gt, [160,160,96], value = np.min(warped_img_gt))\n",
    "\n",
    "            # load mvf\n",
    "            mvf_x = nb.load(os.path.join(save_folder_sub, 'pred_tf'+str(tf)+'_x.nii.gz')).get_fdata()\n",
    "            mvf_y = nb.load(os.path.join(save_folder_sub, 'pred_tf'+str(tf)+'_y.nii.gz')).get_fdata()\n",
    "            mvf_z = nb.load(os.path.join(save_folder_sub, 'pred_tf'+str(tf)+'_z.nii.gz')).get_fdata()\n",
    "          \n",
    "            mvf = np.stack([mvf_x, mvf_y, mvf_z], axis = -1)\n",
    "            if tf == 0:\n",
    "                mvf = np.zeros_like(mvf)\n",
    "                \n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            template_image_torch = torch.from_numpy(template_image).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            mvf_torch = torch.from_numpy(np.transpose(mvf, (3,0,1,2))).unsqueeze(0).float().cuda()\n",
    "            # apply deformation field to template image\n",
    "            warped_img_torch = warp_func.warp_segmentation_from_mvf(template_image_torch, mvf_torch)\n",
    "            warped_img = warped_img_torch.cpu().numpy().squeeze()\n",
    "\n",
    "            nb.save(nb.Nifti1Image(warped_img, affine), os.path.join(save_folder_sub, 'warped_4DCT_pred_tf'+str(tf)+'.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training, Validation and testing dataset were labeled by batch manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import Diffusion_models.functions_collection as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build list for MVF (voxelmorph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/mnt/camca_NAS/4DCT/Patient_lists/'\n",
    "patient_list = pd.read_excel(os.path.join(main_path,'patient_list_final_selection.xlsx'))\n",
    "normal_cases = patient_list[patient_list['patient_class']=='Normal']\n",
    "abnormal_cases = patient_list[patient_list['patient_class']=='Abnormal']\n",
    "print(len(normal_cases),len(abnormal_cases))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 contains 66 patients.\n",
      "Batch 2 contains 64 patients.\n",
      "Batch 3 contains 64 patients.\n",
      "Batch 4 contains 64 patients.\n",
      "Batch 5 contains 64 patients.\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the cases for randomness\n",
    "normal_cases = normal_cases.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "abnormal_cases = abnormal_cases.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Divide each into 5 batches\n",
    "num_batches = 6\n",
    "normal_batches = np.array_split(normal_cases, num_batches)\n",
    "abnormal_batches = np.array_split(abnormal_cases, num_batches)\n",
    "\n",
    "# Combine corresponding normal and abnormal batches\n",
    "combined_batches = []\n",
    "for i in range(num_batches):\n",
    "    combined_batch = pd.concat([normal_batches[i], abnormal_batches[i]], ignore_index=True)\n",
    "    combined_batch['batch'] = i + 1  # Add a column to indicate the batch number\n",
    "    combined_batches.append(combined_batch)\n",
    "\n",
    "# Display results\n",
    "for i, batch in enumerate(combined_batches):\n",
    "    print(f\"Batch {i + 1} contains {len(batch)} patients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = pd.concat(combined_batches, ignore_index=True)\n",
    "\n",
    "# Save to an Excel file\n",
    "final_dataframe.to_excel(os.path.join(main_path, 'patient_list_train_test.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build list for MVF diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/mnt/camca_NAS/4DCT/'\n",
    "patient_list = pd.read_excel(os.path.join(main_path,'Patient_lists/patient_list_train_test_reorder.xlsx'))\n",
    "mvf_predict_list = pd.read_excel(os.path.join(main_path,'mvf_warp0_onecase/check_mvf_max_min.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 322\n"
     ]
    }
   ],
   "source": [
    "row_indices_to_delete = []\n",
    "for i in range(0,patient_list.shape[0]):\n",
    "    patient_id = patient_list.loc[i,'patient_id']\n",
    "    row_in_mvf = mvf_predict_list[mvf_predict_list['patient_id']==patient_id]\n",
    "\n",
    "    if (row_in_mvf['max'].iloc[0] > 20.6): \n",
    "        row_indices_to_delete.append(i)\n",
    "    elif (row_in_mvf['min'].iloc[0] < -20.6): \n",
    "        row_indices_to_delete.append(i)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "patient_list_drop = patient_list.drop(row_indices_to_delete)\n",
    "print(patient_list_drop.shape[0], mvf_predict_list.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list_drop.to_excel(os.path.join(main_path, 'Patient_lists/uc/patient_list_MVF_diffusion_train_test.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGH data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build list for diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/mnt/camca_NAS/4DCT/'\n",
    "patient_list = pd.read_excel(os.path.join(main_path,'Patient_lists/mgh/patient_list_selected.xlsx'))\n",
    "ef_list = pd.read_excel(os.path.join(main_path,'Patient_lists/mgh/patient_list_final_selection_timeframes.xlsx'))\n",
    "mvf_predict_list = pd.read_excel(os.path.join(main_path,'Patient_lists/mgh/check_mvf_max_min.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row indices to delete: [36, 114]\n",
      "208 210\n",
      "208 210\n"
     ]
    }
   ],
   "source": [
    "# drop the one with too large mvf\n",
    "row_indices_to_delete = []\n",
    "for i in range(0,patient_list.shape[0]):\n",
    "    patient_id = patient_list.loc[i,'patient_id']\n",
    "    row_in_mvf = mvf_predict_list[mvf_predict_list['patient_id']==patient_id]\n",
    "    \n",
    "    if (row_in_mvf['max'].iloc[0] > 20.6): \n",
    "        row_indices_to_delete.append(i)\n",
    "    elif (row_in_mvf['min'].iloc[0] < -20.6): \n",
    "        row_indices_to_delete.append(i)\n",
    "\n",
    "print('row indices to delete:', row_indices_to_delete)\n",
    "patient_list_drop = patient_list.drop(row_indices_to_delete)\n",
    "# reset index\n",
    "patient_list_drop = patient_list_drop.reset_index(drop=True)\n",
    "\n",
    "EF_column = []\n",
    "for i in range(0,patient_list_drop.shape[0]):\n",
    "    patient_id = patient_list_drop['patient_id'].iloc[i]\n",
    "    row_in_ef = ef_list[ef_list['patient_id']==patient_id]\n",
    "    EF_column.append(row_in_ef['EF'].iloc[0])\n",
    "patient_list_drop['EF'] = EF_column\n",
    "print(patient_list_drop.shape[0], mvf_predict_list.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low group number: 15  high group number: 193\n"
     ]
    }
   ],
   "source": [
    "# separate by EF\n",
    "ef_low_group = patient_list_drop[patient_list_drop['EF'] < 0.40]\n",
    "ef_high_group = patient_list_drop[patient_list_drop['EF'] >= 0.40]\n",
    "print('low group number:', ef_low_group.shape[0],' high group number:', ef_high_group.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index: 0 batch size: 2\n",
      "batch index: 1 batch size: 1\n",
      "batch index: 2 batch size: 2\n",
      "batch index: 3 batch size: 1\n",
      "batch index: 4 batch size: 1\n",
      "batch index: 5 batch size: 8\n",
      "Batch 1 contains 35 patients.\n",
      "Batch 2 contains 33 patients.\n",
      "Batch 3 contains 34 patients.\n",
      "Batch 4 contains 33 patients.\n",
      "Batch 5 contains 33 patients.\n",
      "Batch 6 contains 40 patients.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Shuffle the EF high cases for randomness\n",
    "normal_cases = ef_high_group.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Divide each into 6 batches\n",
    "num_batches = 6\n",
    "normal_batches = np.array_split(normal_cases, num_batches)\n",
    "# for low EF group\n",
    "def generate_valid_partition():\n",
    "    while True:\n",
    "        split = [random.choice([1, 2]) for _ in range(5)]\n",
    "        if sum(split) == 7:\n",
    "            return split\n",
    "split_sizes = generate_valid_partition()\n",
    "abnormal_batches = []\n",
    "start = 0\n",
    "for size in split_sizes:\n",
    "    abnormal_batches.append(ef_low_group.iloc[start:start + size])\n",
    "    start += size\n",
    "\n",
    "abnormal_batches.append(ef_low_group.iloc[start:])\n",
    "for i, batch in enumerate(abnormal_batches):\n",
    "    print('batch index:', i, 'batch size:', len(batch))\n",
    "\n",
    "\n",
    "# # combine EF high cases with EF low cases (for training group each batch get 1, the rest low cases goes to test groups)\n",
    "combined_batches = []\n",
    "for i in range(num_batches):\n",
    "    combined_batch = pd.concat([normal_batches[i], abnormal_batches[i]], ignore_index=True)\n",
    "    combined_batch['batch'] = i  # Add a column to indicate the batch number\n",
    "    combined_batches.append(combined_batch)\n",
    "\n",
    "# # Display results\n",
    "for i, batch in enumerate(combined_batches):\n",
    "    print(f\"Batch {i + 1} contains {len(batch)} patients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = pd.concat(combined_batches, ignore_index=True)\n",
    "\n",
    "# Save to an Excel file\n",
    "final_dataframe.to_excel(os.path.join(main_path, 'Patient_lists/mgh/patient_list_MVF_diffusion_train_test.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# third party imports \n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import nibabel as nb\n",
    "import cv2\n",
    "import ast\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.ndimage import center_of_mass\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import Diffusion_motion_field.Build_lists.Build_list as Build_list\n",
    "import Diffusion_motion_field.functions_collection as ff\n",
    "from Diffusion_motion_field.common_metrics_on_video_quality.fvd.styleganv.fvd import get_fvd_feats, frechet_distance, load_i3d_pretrained\n",
    "\n",
    "main_path = '/mnt/camca_NAS/4DCT/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load patient list\n",
    "data_sheet = os.path.join(os.path.dirname(main_path),'Patient_lists/mgh/patient_list_MVF_diffusion_train_test.xlsx')\n",
    "b = Build_list.Build(data_sheet)\n",
    "patient_class_list, patient_id_list,_ = b.__build__(batch_list = [5])\n",
    "# patient_class_list = patient_class_list[0:2]\n",
    "# patient_id_list = patient_id_list[0:2]\n",
    "\n",
    "timeframe_info = pd.read_excel('/mnt/camca_NAS/4DCT/Patient_lists/mgh/patient_list_final_selection_timeframes.xlsx')\n",
    "\n",
    "trial_name = 'MVF_EDM_down_10tf_imgcon_EFcon'\n",
    "epoch = 2350\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare all data for original and generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = np.zeros((len(patient_id_list), 10,128,128,96))\n",
    "generated_data_factual = np.zeros((len(patient_id_list), 10,128,128,96))\n",
    "generated_data_counterfactual = np.zeros((len(patient_id_list),3,10, 128,128,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(patient_id_list)):\n",
    "\n",
    "#     patient_class = patient_class_list[i]\n",
    "#     patient_id = patient_id_list[i]\n",
    "\n",
    "#     row = timeframe_info[timeframe_info['patient_id'] == patient_id]\n",
    "#     sampled_time_frame_list = ast.literal_eval(row['sampled_time_frame_list'].iloc[0])\n",
    "#     normalized_time_frame_list = ast.literal_eval(row['normalized_time_frame_list_copy'].iloc[0])\n",
    "#     picked_tf_normalized = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     picked_tf = [sampled_time_frame_list[normalized_time_frame_list.index(picked_tf_normalized[iii])] for iii in range(0,len(picked_tf_normalized))]  \n",
    "\n",
    "#     # get the segmentation\n",
    "#     seg_file = os.path.join('/mnt/camca_NAS/4DCT/mgh_data/predicted_seg/',patient_class, patient_id, 'pred_s_0.nii.gz')\n",
    "#     seg = nb.load(seg_file).get_fdata(); seg = np.round(seg); seg[seg!= 1] = 0\n",
    "#     # find the center of LV = 1\n",
    "#     center = center_of_mass(seg)\n",
    "#     center_x, center_y, center_z = int(center[0]), int(center[1]), int(center[2])\n",
    "#     x_start = max(0, center_x - 64); x_end = x_start + 128\n",
    "#     y_start = max(0, center_y - 64); y_end = y_start + 128\n",
    "\n",
    "\n",
    "#     # get original data\n",
    "#     folder = os.path.join('/mnt/camca_NAS/4DCT/reference/',patient_class, patient_id, 'image_warped_mvf_original')\n",
    "#     for tf_n in range(0, len(picked_tf)):\n",
    "#         original_data[i, tf_n, ... ] = nb.load(os.path.join(folder, str(picked_tf[tf_n]) + '.nii.gz')).get_fdata()[x_start:x_end, y_start:y_end, :]\n",
    "    \n",
    "#     # get generated data factural\n",
    "#     folder = os.path.join('/mnt/camca_NAS/4DCT/models/',trial_name,'pred_mvf', patient_class, patient_id,  'epoch' + str(epoch)+ '_0')\n",
    "#     for tf_n in range(0, len(picked_tf)):\n",
    "#         generated_data_factual[i, tf_n, ...] = nb.load(os.path.join(folder, 'warped_img_pred_tf' + str(picked_tf[tf_n]) + '.nii.gz')).get_fdata()[x_start:x_end, y_start:y_end, :]\n",
    "    \n",
    "#     # get generated data counterfactual\n",
    "#     folder = os.path.join('/mnt/camca_NAS/4DCT/models/',trial_name,'pred_mvf', patient_class, patient_id,  'epoch' + str(epoch)+  '_1')\n",
    "#     for tf_n in range(0,len(picked_tf)):\n",
    "#         generated_data_counterfactual[i, 0,tf_n, ...] = nb.load(os.path.join(folder, 'warped_img_pred_tf' + str(picked_tf[tf_n]) +'.nii.gz')).get_fdata()[x_start:x_end, y_start:y_end, :]\n",
    "#     folder = os.path.join('/mnt/camca_NAS/4DCT/models/',trial_name,'pred_mvf', patient_class, patient_id,  'epoch' + str(epoch)+  '_2')\n",
    "#     for tf_n in range(0,len(picked_tf)):\n",
    "#         generated_data_counterfactual[i, 1,tf_n, ...] = nb.load(os.path.join(folder, 'warped_img_pred_tf' + str(picked_tf[tf_n]) +'.nii.gz')).get_fdata()[x_start:x_end, y_start:y_end, :]\n",
    "#     folder = os.path.join('/mnt/camca_NAS/4DCT/models/',trial_name,'pred_mvf', patient_class, patient_id,  'epoch' + str(epoch)+  '_3')\n",
    "#     for tf_n in range(0,len(picked_tf)):\n",
    "#         generated_data_counterfactual[i, 2,tf_n, ...] = nb.load(os.path.join(folder, 'warped_img_pred_tf' + str(picked_tf[tf_n]) +'.nii.gz')).get_fdata()[x_start:x_end, y_start:y_end, :]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load existing data\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'original_data_sampled_for_quantitative.npy')) == 0:\n",
    "  \n",
    "    original_data_sampled = original_data[...,::3]\n",
    "    generated_data_factual_sampled = generated_data_factual[...,::3]\n",
    "    generated_data_counterfactual_sampled = generated_data_counterfactual[...,::3]\n",
    "    print('original_data_sample shape:', original_data_sampled.shape)\n",
    "\n",
    "    np.save(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'original_data_sampled_for_quantitative.npy'), original_data_sampled)\n",
    "    np.save(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'generated_data_factual_sampled_for_quantitative.npy'), generated_data_factual_sampled)\n",
    "    np.save(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'generated_data_counterfactual_sampled_for_quantitative.npy'), generated_data_counterfactual_sampled)\n",
    "\n",
    "else:\n",
    "    print('load existing data')\n",
    "    original_data_sampled = np.load(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'original_data_sampled_for_quantitative.npy'))\n",
    "    generated_data_factual_sampled = np.load(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'generated_data_factual_sampled_for_quantitative.npy'))\n",
    "    generated_data_counterfactual_sampled = np.load(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'generated_data_counterfactual_sampled_for_quantitative.npy'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained InceptionV3\n",
    "inception = models.inception_v3(pretrained=True)\n",
    "inception.fc = torch.nn.Identity()  # Remove classification head\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inception.eval().to(device)\n",
    "\n",
    "def extract_inception_features(slices_np):  # [N, 1, H, W]\n",
    "    tensor = torch.from_numpy(slices_np).float()\n",
    "    tensor = tensor / 255.0  # Normalize\n",
    "    tensor = F.interpolate(tensor, size=(299, 299), mode='bilinear')  # Resize\n",
    "    tensor = tensor.repeat(1, 3, 1, 1)  # Convert to RGB\n",
    "    with torch.no_grad():\n",
    "        feats = inception(tensor.cuda())  # [N, 2048]\n",
    "    return feats.cpu().numpy()\n",
    "\n",
    "def calculate_fid(mu1, sigma1, mu2, sigma2):\n",
    "    diff = mu1 - mu2\n",
    "    covmean = sqrtm(sigma1 @ sigma2)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features_list = []\n",
    "factual_features_list = []\n",
    "counterfactual_features_list = []\n",
    "for i in range(0, original_data_sampled.shape[0]):\n",
    "    \n",
    "    # Extract features for original data\n",
    "    original_patient = original_data_sampled[i, :, :, :, :].reshape(-1, 1, 128, 128)  # Reshape to [N, 1, H, W]\n",
    "    original_features_list.append(extract_inception_features(original_patient))\n",
    "\n",
    "    # Extract features for generated factual data\n",
    "    factual_patient = generated_data_factual_sampled[i, :, :, :, :].reshape(-1, 1, 128, 128)  # Reshape to [N, 1, H, W]\n",
    "    factual_features_list.append(extract_inception_features(factual_patient))\n",
    "\n",
    "    # Extract features for generated counterfactual data\n",
    "    counterfactual_patient = generated_data_counterfactual_sampled[i, :, :, :, :].reshape(-1, 1, 128, 128)  # Reshape to [N, 1, H, W]\n",
    "    counterfactual_features_list.append(extract_inception_features(counterfactual_patient))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "original_features = np.array(original_features_list).reshape(-1, 2048)\n",
    "factual_features = np.array(factual_features_list).reshape(-1, 2048)\n",
    "counterfactual_features = np.array(counterfactual_features_list).reshape(-1, 2048)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID factual: 11.699855959981884\n",
      "FID counterfactual: 10.53149512930959\n"
     ]
    }
   ],
   "source": [
    "mu_original = np.mean(original_features, axis=0)\n",
    "sigma_original = np.cov(original_features, rowvar=False)\n",
    "mu_factual = np.mean(factual_features, axis=0)\n",
    "sigma_factual = np.cov(factual_features, rowvar=False)\n",
    "mu_counterfactual = np.mean(counterfactual_features, axis=0)\n",
    "sigma_counterfactual = np.cov(counterfactual_features, rowvar=False)\n",
    "\n",
    "fid_factual = calculate_fid(mu_original, sigma_original, mu_factual, sigma_factual)\n",
    "fid_counterfactual = calculate_fid(mu_original, sigma_original, mu_counterfactual, sigma_counterfactual)\n",
    "print('FID factual:', fid_factual)\n",
    "print('FID counterfactual:', fid_counterfactual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(x):\n",
    "    # if greyscale images add channel\n",
    "    if x.shape[-3] == 1:\n",
    "        x = x.repeat(1, 1, 3, 1, 1)\n",
    "\n",
    "    # permute BTCHW -> BCTHW\n",
    "    x = x.permute(0, 2, 1, 3, 4) \n",
    "\n",
    "    return x\n",
    "\n",
    "def calculate_fvd(videos1, videos2, device, only_final=False):\n",
    "\n",
    "    # videos [batch_size, timestamps, channel, h, w]\n",
    "    \n",
    "    assert videos1.shape == videos2.shape\n",
    "\n",
    "    i3d = load_i3d_pretrained(device=device)\n",
    "    fvd_results = []\n",
    "\n",
    "    # support grayscale input, if grayscale -> channel*3\n",
    "    # BTCHW -> BCTHW\n",
    "    # videos -> [batch_size, channel, timestamps, h, w]\n",
    "\n",
    "    videos1 = trans(videos1)\n",
    "    videos2 = trans(videos2)\n",
    "\n",
    "    # print('after trans videos1 shape: ', videos1.shape, ' videos2 shape: ', videos2.shape)\n",
    "\n",
    "    fvd_results = []\n",
    "\n",
    "    assert videos1.shape[2] >= 10, \"for calculate FVD, each clip_timestamp must >= 10\"\n",
    "\n",
    "    # videos_clip [batch_size, channel, timestamps, h, w]\n",
    "    videos_clip1 = videos1\n",
    "    videos_clip2 = videos2\n",
    "\n",
    "    # get FVD features\n",
    "    feats1 = get_fvd_feats(videos_clip1, i3d=i3d, device=device)\n",
    "    feats2 = get_fvd_feats(videos_clip2, i3d=i3d, device=device)\n",
    "\n",
    "    # calculate FVD\n",
    "    fvd_results.append(frechet_distance(feats1, feats2))\n",
    "    \n",
    "    result = {\n",
    "        \"value\": fvd_results,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_arr = np.random.randint(0, 3, size=40)\n",
    "# np.save(os.path.join('/mnt/camca_NAS/4DCT/models/', 'MVF_EDM_down_10tf_imgcon_EFcon_warp_orires', 'random_pick_counterfactual_for_FVD.npy'), random_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do FVD slice by slice\n",
    "random_arr = np.load(os.path.join('/mnt/camca_NAS/4DCT/models/', 'MVF_EDM_down_10tf_imgcon_EFcon_warp_orires', 'random_pick_counterfactual_for_FVD.npy'))\n",
    "\n",
    "result_fvd_factual = []\n",
    "result_fvd_counterfactual = []\n",
    "for slice_n in range(0,original_data_sampled.shape[-1]):\n",
    "    original_data_sampled_normalized = (original_data_sampled - np.min(original_data_sampled)) / (np.max(original_data_sampled) - np.min(original_data_sampled))\n",
    "    generated_data_factual_sampled_normalized = (generated_data_factual_sampled - np.min(generated_data_factual_sampled)) / (np.max(generated_data_factual_sampled) - np.min(generated_data_factual_sampled))\n",
    "    generated_data_counterfactual_sampled_normalized_raw = (generated_data_counterfactual_sampled - np.min(generated_data_counterfactual_sampled)) / (np.max(generated_data_counterfactual_sampled) - np.min(generated_data_counterfactual_sampled))\n",
    "    \n",
    "    # for each counterfactual, pick one sample (since this fvd function needs same shape for video 1 and video 2)\n",
    "    generated_data_counterfactual_sampled_normalized = np.zeros_like(generated_data_counterfactual_sampled_normalized_raw[:,0,...])\n",
    "    for ii in range(0, generated_data_counterfactual_sampled_normalized.shape[0]):\n",
    "        generated_data_counterfactual_sampled_normalized[ii, ...] = generated_data_counterfactual_sampled_normalized_raw[ii, random_arr[ii], ...]\n",
    "\n",
    "    original_data_slice = torch.from_numpy(original_data_sampled_normalized[..., slice_n]).unsqueeze(2).float()\n",
    "    generated_data_factual_slice = torch.from_numpy(generated_data_factual_sampled_normalized[..., slice_n]).unsqueeze(2).float()\n",
    "    generated_data_counterfactual_slice = torch.from_numpy(generated_data_counterfactual_sampled_normalized[..., slice_n]).unsqueeze(2).float()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    result_factual = calculate_fvd(original_data_slice, generated_data_factual_slice, device)\n",
    "    result_counterfactual = calculate_fvd(original_data_slice, generated_data_counterfactual_slice, device)\n",
    "    result_fvd_factual.append(result_factual['value'][0])\n",
    "    result_fvd_counterfactual.append(result_counterfactual['value'][0])\n",
    "\n",
    "    print('slice: ', slice_n, ' FVD factual: ', result_fvd_factual[-1], ' FVD counterfactual: ', result_fvd_counterfactual[-1])\n",
    "\n",
    "df = pd.DataFrame({'slice_sampled': list(range(0,original_data_sampled.shape[-1])),\n",
    "                   'fvd_factual': result_fvd_factual, \n",
    "                   'fvd_counterfactual': result_fvd_counterfactual})\n",
    "df.to_excel(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'fvd_results.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0, original_data_sampled.shape[0]):\n",
    "    patient_class = patient_class_list[i]\n",
    "    patient_id = patient_id_list[i]\n",
    "    ssim_factual_patient = []\n",
    "    mae_factual_patient = []\n",
    "    rmse_factual_patient = []\n",
    "    for tf in range(0, original_data_sampled.shape[1]):\n",
    "        mae, _, rmse, _, ssim = ff.compare(original_data_sampled[i, tf, ...], generated_data_factual_sampled[i, tf, ...])\n",
    "        ssim_factual_patient.append(ssim)\n",
    "        mae_factual_patient.append(mae)\n",
    "        rmse_factual_patient.append(rmse)\n",
    "    ssim_factual_patient = sum(ssim_factual_patient) / len(ssim_factual_patient)\n",
    "    mae_factual_patient = sum(mae_factual_patient) / len(mae_factual_patient)\n",
    "    rmse_factual_patient = sum(rmse_factual_patient) / len(rmse_factual_patient)\n",
    "\n",
    "    results.append([patient_class, patient_id, ssim_factual_patient, mae_factual_patient, rmse_factual_patient])\n",
    "    df_results = pd.DataFrame(results, columns=['patient_class', 'patient_id', 'ssim', 'mae', 'rmse'])\n",
    "    df_results.to_excel(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'ssim_mae_rmse_factual.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0, original_data_sampled.shape[0]):\n",
    "    for round_test in range(0, 3):\n",
    "        patient_class = patient_class_list[i]\n",
    "        patient_id = patient_id_list[i]\n",
    "        ssim_factual_patient = []\n",
    "        mae_factual_patient = []\n",
    "        rmse_factual_patient = []\n",
    "        for tf in range(0, original_data_sampled.shape[1]):\n",
    "            mae, _, rmse, _, ssim = ff.compare(original_data_sampled[i, tf, ...], generated_data_counterfactual_sampled[i, round_test,tf, ...])\n",
    "            ssim_factual_patient.append(ssim)\n",
    "            mae_factual_patient.append(mae)\n",
    "            rmse_factual_patient.append(rmse)\n",
    "        ssim_factual_patient = sum(ssim_factual_patient) / len(ssim_factual_patient)\n",
    "        mae_factual_patient = sum(mae_factual_patient) / len(mae_factual_patient)\n",
    "        rmse_factual_patient = sum(rmse_factual_patient) / len(rmse_factual_patient)\n",
    "\n",
    "        results.append([patient_class, patient_id,round_test, ssim_factual_patient, mae_factual_patient, rmse_factual_patient])\n",
    "        df_results = pd.DataFrame(results, columns=['patient_class', 'patient_id', 'round_test','ssim', 'mae', 'rmse'])\n",
    "        df_results.to_excel(os.path.join('/mnt/camca_NAS/4DCT/models/', trial_name, 'ssim_mae_rmse_counterfactual.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ef_list_factual shape:  (40, 6) ef_list_counterfactual shape:  (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# ef_list = pd.read_excel(os.path.join('/mnt/camca_NAS/4DCT/models/', 'MVF_EDM_down_10tf_imgcon_EFcon', 'EF_from_warploss_results_epoch2350_edited.xlsx'))\n",
    "# ef_list = pd.read_excel(os.path.join('/mnt/camca_NAS/4DCT/models/', 'MVF_EDM_down_10tf_imgcon_EFcon_EFpredict_trial2', 'EF_from_warploss_results_epoch1410_edited.xlsx'))\n",
    "ef_list = pd.read_excel(os.path.join('/mnt/camca_NAS/4DCT/models/', 'MVF_EDM_down_10tf_imgcon_EFcon_warp_orires', 'EF_from_warploss_results_epoch1930_edited.xlsx'))\n",
    "ef_list = ef_list[:-1]\n",
    "ef_list = ef_list[['patient_class', 'patient_id', 'round_test', 'preset_EF', 'pred_EF']]\n",
    "\n",
    "# get a new column for abs difference\n",
    "ef_list['diff'] = abs(ef_list['preset_EF'] - ef_list['pred_EF'])\n",
    "\n",
    "ef_list_factual = ef_list[ef_list['round_test'] == 0]\n",
    "ef_list_counterfactual = ef_list[ef_list['round_test'] != 0]\n",
    "print('ef_list_factual shape: ', ef_list_factual.shape, 'ef_list_counterfactual shape: ', ef_list_counterfactual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factual EF abs diff mean:  0.024431153483688833  std:  0.02080821568749653  correlation:  0.9612665416914933  pearson r:  0.9897574796641788  p-value:  9.735754937768578e-34\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and std \n",
    "factual_mean = ef_list_factual['diff'].mean()\n",
    "factual_std = ef_list_factual['diff'].std()\n",
    "r2 = r2_score(ef_list_factual[\"preset_EF\"], ef_list_factual[\"pred_EF\"])\n",
    "r, p_value = pearsonr(ef_list_factual[\"preset_EF\"], ef_list_factual[\"pred_EF\"])\n",
    "print('Factual EF abs diff mean: ', factual_mean, ' std: ', factual_std, ' correlation: ', r2, ' pearson r: ', r, ' p-value: ', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual EF abs diff mean:  0.025082963934168218  std:  0.01938759338660615  correlation:  0.9738940654257792  pearson r:  0.9952109461575658  p-value:  5.025770755091874e-121\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and std for counterfactual\n",
    "counterfactual_mean = ef_list_counterfactual['diff'].mean()\n",
    "counterfactual_std = ef_list_counterfactual['diff'].std()\n",
    "r2_counterfactual = r2_score(ef_list_counterfactual[\"preset_EF\"], ef_list_counterfactual[\"pred_EF\"])\n",
    "r_counterfactual, p_value_counterfactual = pearsonr(ef_list_counterfactual[\"preset_EF\"], ef_list_counterfactual[\"pred_EF\"])\n",
    "print('Counterfactual EF abs diff mean: ', counterfactual_mean, ' std: ', counterfactual_std, ' correlation: ', r2_counterfactual, ' pearson r: ', r_counterfactual, ' p-value: ', p_value_counterfactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
